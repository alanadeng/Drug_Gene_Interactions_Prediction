{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, precision_recall_curve\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/dgidb/embeddings/'\n",
    "\n",
    "#emd = 'metapath2vec_'\n",
    "#emd = 'node2vec_'\n",
    "#emd = 'struc2vec_'\n",
    "#emd = 'deepwalk_'\n",
    "emd = 'word2vec_'\n",
    "#emd = 'bine_'\n",
    "\n",
    "drug_embeddings = pd.read_csv(file_path+emd+'drug_embeddings.csv', header=None, index_col=0).dropna(axis=1)\n",
    "gene_embeddings = pd.read_csv(file_path+emd+'gene_embeddings.csv', header=None, index_col=0).dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_path = '../data/dgidb/train_test/'\n",
    "\n",
    "ns = '/uniform'\n",
    "#ns = '/feature'\n",
    "#ns = '/topology'\n",
    "\n",
    "\n",
    "train_edge = pd.read_csv(tt_path+emd[:-1]+ns+\"/train.csv\")\n",
    "test_edge = pd.read_csv(tt_path+emd[:-1]+ns+\"/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from CSV and create edge indices\n",
    "def load_data_and_create_edges(file_path, node_to_idx):\n",
    "    df = pd.read_csv(file_path)\n",
    "    edge_list = df[df['label'] == 1][['gene', 'drug']].values.tolist()\n",
    "    neg_edge_list = df[df['label'] == 0][['gene', 'drug']].values.tolist()\n",
    "\n",
    "    # Creating edge indices\n",
    "    edge_index = [[node_to_idx[u], node_to_idx[v]] for u, v in edge_list]\n",
    "    neg_edge_index = [[node_to_idx[u], node_to_idx[v]] for u, v in neg_edge_list]\n",
    "\n",
    "    return torch.tensor(edge_index, dtype=torch.long).t(), torch.tensor(neg_edge_index, dtype=torch.long).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure embeddings have the same dimensionality\n",
    "assert gene_embeddings.shape[1] == drug_embeddings.shape[1], \"Embeddings must have the same dimensionality\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate gene and drug embeddings\n",
    "node_embeddings = torch.tensor(np.concatenate((gene_embeddings, drug_embeddings), axis=0), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine unique genes and drugs from both training and testing data\n",
    "unique_genes_train = set(pd.read_csv(tt_path+emd[:-1]+ns+\"/train.csv\")['gene'].unique())\n",
    "unique_drugs_train = set(pd.read_csv(tt_path+emd[:-1]+ns+\"/train.csv\")['drug'].unique())\n",
    "unique_genes_test = set(pd.read_csv(tt_path+emd[:-1]+ns+\"/test.csv\")['gene'].unique())\n",
    "unique_drugs_test = set(pd.read_csv(tt_path+emd[:-1]+ns+\"/test.csv\")['drug'].unique())\n",
    "\n",
    "all_genes = unique_genes_train.union(unique_genes_test)\n",
    "all_drugs = unique_drugs_train.union(unique_drugs_test)\n",
    "\n",
    "# Create a comprehensive node_to_idx mapping\n",
    "node_to_idx = {node: idx for idx, node in enumerate(list(all_genes) + list(all_drugs))}\n",
    "\n",
    "# Now load train and test data\n",
    "train_edge_index, train_neg_edge_index = load_data_and_create_edges(tt_path+emd[:-1]+ns+\"/train.csv\", node_to_idx)\n",
    "test_edge_index, test_neg_edge_index = load_data_and_create_edges(tt_path+emd[:-1]+ns+\"/test.csv\", node_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data\n",
    "train_edge_index, train_neg_edge_index = load_data_and_create_edges(tt_path+emd[:-1]+ns+\"/train.csv\", node_to_idx)\n",
    "test_edge_index, test_neg_edge_index = load_data_and_create_edges(tt_path+emd[:-1]+ns+\"/test.csv\", node_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph construction\n",
    "num_features = node_embeddings.shape[1]\n",
    "data = Data(x=node_embeddings, edge_index=train_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.edge_predictor = torch.nn.Linear(2 * hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    node_embeddings = model(data.x, train_edge_index)\n",
    "    pos_edge_features = torch.cat([node_embeddings[train_edge_index[0]], node_embeddings[train_edge_index[1]]], dim=1)\n",
    "    neg_edge_features = torch.cat([node_embeddings[train_neg_edge_index[0]], node_embeddings[train_neg_edge_index[1]]], dim=1)\n",
    "    all_edge_features = torch.cat([pos_edge_features, neg_edge_features], dim=0)\n",
    "    pos_labels = torch.ones(pos_edge_features.size(0), dtype=torch.float)\n",
    "    neg_labels = torch.zeros(neg_edge_features.size(0), dtype=torch.float)\n",
    "    all_labels = torch.cat([pos_labels, neg_labels], dim=0)\n",
    "    edge_scores = model.edge_predictor(all_edge_features).squeeze(1)\n",
    "    loss = criterion(edge_scores, all_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        node_embeddings = model(data.x, test_edge_index)\n",
    "        pos_edge_features = torch.cat([node_embeddings[test_edge_index[0]], node_embeddings[test_edge_index[1]]], dim=1)\n",
    "        neg_edge_features = torch.cat([node_embeddings[test_neg_edge_index[0]], node_embeddings[test_neg_edge_index[1]]], dim=1)\n",
    "        all_edge_features = torch.cat([pos_edge_features, neg_edge_features], dim=0)\n",
    "        pos_labels = torch.ones(pos_edge_features.size(0), dtype=torch.float)\n",
    "        neg_labels = torch.zeros(neg_edge_features.size(0), dtype=torch.float)\n",
    "        all_labels = torch.cat([pos_labels, neg_labels], dim=0)\n",
    "        edge_scores = model.edge_predictor(all_edge_features).squeeze(1)\n",
    "        loss = criterion(edge_scores, all_labels)\n",
    "        return loss.item(), edge_scores, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters to tune\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "hidden_channels_options = [16, 32]\n",
    "num_layers_options = [1, 2]\n",
    "dropout_rates = [0, 0.5]\n",
    "\n",
    "# Placeholder for best model and performance\n",
    "best_auc = 0\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "num_epoch = 500\n",
    "\n",
    "# Hyperparameter tuning loop\n",
    "for lr, hidden_channels, num_layers, dropout in itertools.product(learning_rates, hidden_channels_options, num_layers_options, dropout_rates):\n",
    "    \n",
    "    # Initialize model\n",
    "    model = GCN(num_features, hidden_channels, num_layers, dropout)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epoch):  # Adjust the number of epochs\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        # Assume train_edge_index and train_labels are defined\n",
    "        out = model(data.x, train_edge_index)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Assume validation_edge_index and validation_labels are defined\n",
    "        out = model(data.x, validation_edge_index)\n",
    "        auc_score = roc_auc_score(validation_labels.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "    # Update best model if current model is better\n",
    "    if auc_score > best_auc:\n",
    "        best_auc = auc_score\n",
    "        best_params = {'lr': lr, 'hidden_channels': hidden_channels, 'num_layers': num_layers, 'dropout': dropout}\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best AUROC:\", best_auc)\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model on the entire dataset (train + validation) with best hyperparameters\n",
    "model = GCN(num_features, best_params['hidden_channels'], best_params['num_layers'], best_params['dropout'])\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_params['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 500\n",
    "\n",
    "# Train and test the model\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in tqdm(range(num_epoch)):\n",
    "    train_loss = train()\n",
    "    test_loss, test_scores, test_labels = test()\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_scores, test_labels = test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for saving results\n",
    "res_path = '../res/gcn/' + emd[:-1] + ns \n",
    "os.makedirs(res_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and testing losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='Testing Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Testing Losses Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plots_file_path = res_path + '/loss.png'\n",
    "plt.savefig(plots_file_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model and calculate metrics\n",
    "def evaluate_model():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        node_embeddings = model(data.x, test_edge_index)\n",
    "        pos_edge_features = torch.cat([node_embeddings[test_edge_index[0]], node_embeddings[test_edge_index[1]]], dim=1)\n",
    "        neg_edge_features = torch.cat([node_embeddings[test_neg_edge_index[0]], node_embeddings[test_neg_edge_index[1]]], dim=1)\n",
    "        all_edge_features = torch.cat([pos_edge_features, neg_edge_features], dim=0)\n",
    "        edge_scores = model.edge_predictor(all_edge_features).squeeze(1)\n",
    "        edge_scores = torch.sigmoid(edge_scores).cpu().numpy()\n",
    "        all_labels = torch.cat([torch.ones(pos_edge_features.size(0)), torch.zeros(neg_edge_features.size(0))], dim=0).cpu().numpy()\n",
    "\n",
    "        y_pred = (edge_scores >= 0.5).astype(int)\n",
    "        accuracy = accuracy_score(all_labels, y_pred)\n",
    "        precision_scr = precision_score(all_labels, y_pred)\n",
    "        recall_scr = recall_score(all_labels, y_pred)\n",
    "        f1 = f1_score(all_labels, y_pred)\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(all_labels, edge_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        precision, recall, _ = precision_recall_curve(all_labels, edge_scores)\n",
    "        pr_auc = auc(recall, precision)\n",
    "\n",
    "        return accuracy, precision_scr, recall_scr, f1, fpr, tpr, roc_auc, precision, recall, pr_auc\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision_scr, recall_scr, f1, fpr, tpr, roc_auc, precision, recall, pr_auc = evaluate_model()\n",
    "\n",
    "# Plot and save ROC and PRC curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='grey', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, color='green', lw=2, label=f'PR curve (area = {pr_auc:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plots_file_path = res_path + '/plot.png'\n",
    "plt.savefig(plots_file_path)\n",
    "plt.show()\n",
    "\n",
    "# Save metrics to file\n",
    "metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision_scr,\n",
    "    'Recall': recall_scr,\n",
    "    'F1 Score': f1,\n",
    "    'AUROC': roc_auc,\n",
    "    'AUPRC': pr_auc\n",
    "}\n",
    "metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Value'])\n",
    "metrics_file_path = res_path + '/metrics.csv'\n",
    "metrics_df.to_csv(metrics_file_path)\n",
    "\n",
    "# Save ROC and PRC data to CSV\n",
    "roc_df = pd.DataFrame({'fpr': fpr, 'tpr': tpr})\n",
    "roc_df.to_csv(res_path + '/roc.csv', index=None)\n",
    "\n",
    "prc_df = pd.DataFrame({'precision': precision, 'recall': recall})\n",
    "prc_df.to_csv(res_path + '/prc.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
