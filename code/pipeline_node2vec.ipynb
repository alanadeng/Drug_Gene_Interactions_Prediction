{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import graph_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Data, Generate Graph & Embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = ['preprocessed_34_10.tsv', 'preprocessed_42_10.tsv']\n",
    "\n",
    "###### edit here to change dataset ######\n",
    "dat_idx = 0 # choose from [0,1]\n",
    "#########################################\n",
    "\n",
    "file_path = \"../data/\" + data[dat_idx]\n",
    "df = pd.read_csv(file_path, sep='\\t', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "G = graph_prep.nx_drug_gene_bipartite(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Computing transition probabilities:   0%|          | 0/1637 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "908b7d789d804c45815118c2c5f2ee66"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 4): 100%|██████████| 75/75 [00:14<00:00,  5.31it/s]"
     ]
    }
   ],
   "source": [
    "embedding_methods = ['node2vec', 'deepwalk']\n",
    "\n",
    "###### edit here to change the node embedding method ######\n",
    "emd_idx = 0 # choose from [0,1]\n",
    "#########################################\n",
    "\n",
    "if embedding_methods[emd_idx] == 'node2vec':\n",
    "    node_embeddings = graph_prep.node2vec_embedding(G)\n",
    "elif embedding_methods[emd_idx] == 'deepwalk':\n",
    "    node_embeddings = graph_prep.deepwalk_embedding(G)\n",
    "else:\n",
    "    raise ValueError(\"Invalid embedding methods.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Functions & Configurations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, precision_recall_curve, auc\n",
    "from scipy.stats import loguniform, randint\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store metrics and models\n",
    "metrics = {}\n",
    "models = {}\n",
    "roc_data = {}\n",
    "prc_data = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Hyperparameter distributions\n",
    "lr_param_dist = {'C': loguniform(0.001, 1000)}\n",
    "xgb_param_dist = {\n",
    "    'learning_rate': loguniform(0.01, 0.2),\n",
    "    'n_estimators': randint(50, 1000),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'min_child_weight': randint(1, 10),\n",
    "    'gamma': loguniform(0.001, 1),\n",
    "    'subsample': loguniform(0.5, 1),\n",
    "    'colsample_bytree': loguniform(0.5, 1)\n",
    "}\n",
    "svm_param_dist = {'C': loguniform(0.001, 1000), 'gamma': loguniform(0.001, 1)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Softmax Layer Neural Network\n",
    "class SoftmaxNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SoftmaxNN, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.functional.softmax(self.fc(x), dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Function for hyperparameter tuning\n",
    "def tune_hyperparameters(clf, param_dist, X_train, y_train):\n",
    "    random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=100, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Function for training and evaluating the model\n",
    "def train_evaluate_model(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_probs = clf.predict_proba(X_test)[:, 1]\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred),\n",
    "        'AUC-ROC': roc_auc_score(y_test, y_probs),\n",
    "        'AUC-PRC': auc(recall, precision)\n",
    "    }\n",
    "\n",
    "    roc_data = roc_curve(y_test, y_probs)\n",
    "    prc_data = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "    print(\"Metrics: \", end='')\n",
    "    print(metrics)\n",
    "    # print(\"AUC-ROC: \")\n",
    "    # print(roc_data)\n",
    "    # print(\"AUC-PRC: \")\n",
    "    # print(prc_data)\n",
    "\n",
    "    return metrics, roc_data, prc_data\n",
    "\n",
    "\n",
    "# Function for training and evaluating the neural network\n",
    "def train_evaluate_nn(model, X_train, X_test, y_train, y_test, epochs=100, learning_rate=0.001):\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_torch = torch.tensor(X_train.astype(np.float32))\n",
    "    X_test_torch = torch.tensor(X_test.astype(np.float32))\n",
    "    y_train_torch = torch.tensor(y_train.astype(np.int64))\n",
    "    y_test_torch = torch.tensor(y_test.astype(np.int64))\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_torch)\n",
    "        loss = criterion(outputs, y_train_torch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_torch = model(X_test_torch)\n",
    "        y_pred = torch.max(y_pred_torch, 1)[1].numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "    return metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def plot_metrics(roc_data, prc_data, save_fig=False, filename='model_evaluation_plots.png'):\n",
    "    # Unpack ROC data\n",
    "    fpr, tpr, _ = roc_data\n",
    "    # Unpack Precision-Recall data\n",
    "    precision, recall, _ = prc_data\n",
    "\n",
    "    # Create subplots\n",
    "    fig, (ax_roc, ax_prc) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Plot ROC Curve\n",
    "    ax_roc.plot(fpr, tpr, color='blue', lw=2, label='ROC curve')\n",
    "    ax_roc.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    ax_roc.set_xlim([0.0, 1.0])\n",
    "    ax_roc.set_ylim([0.0, 1.05])\n",
    "    ax_roc.set_xlabel('False Positive Rate')\n",
    "    ax_roc.set_ylabel('True Positive Rate')\n",
    "    ax_roc.set_title('ROC Curve')\n",
    "    ax_roc.legend(loc=\"lower right\")\n",
    "\n",
    "    # Plot Precision-Recall Curve\n",
    "    ax_prc.plot(recall, precision, color='green', lw=2, label='PR curve')\n",
    "    ax_prc.set_xlim([0.0, 1.0])\n",
    "    ax_prc.set_ylim([0.0, 1.05])\n",
    "    ax_prc.set_xlabel('Recall')\n",
    "    ax_prc.set_ylabel('Precision')\n",
    "    ax_prc.set_title('Precision-Recall Curve')\n",
    "    ax_prc.legend(loc=\"lower left\")\n",
    "\n",
    "    # Show the plots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    if save_fig:\n",
    "        plt.savefig(filename, dpi=300)\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sampling, Train-Test-Split, Dimensionality Reduction, Classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "svm\n",
      "----------------------------\n",
      "Sampling Method:  random_under\n",
      "PCA applied. PCA Explained Variance:  0.8967276670737192\n",
      "Stratified Train-Test Split:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_models = ['lr', 'svm', 'xgb', 'softmax']\n",
    "\n",
    "###### edit here to change classification model ######\n",
    "clf_idx = 0 # choose from [0,1]\n",
    "#########################################\n",
    "\n",
    "for i in range (1, len(classification_models)):\n",
    "    clf_idx = 1\n",
    "    print(\"---------------------------------------------------------------------------\")\n",
    "    print(classification_models[clf_idx])\n",
    "    for sampling in ['random_under', 'distance_under']:\n",
    "        for if_stratified in [True, False]:\n",
    "            for if_PCA in [True, False]:\n",
    "\n",
    "                print(\"----------------------------\")\n",
    "\n",
    "                # sampling\n",
    "                sampled_edges, sampled_labels = graph_prep.negative_sampling(df, node_embeddings, method=sampling)\n",
    "                print(\"Sampling Method: \", sampling)\n",
    "\n",
    "                if if_PCA:\n",
    "                    # dimensionality reduction\n",
    "                    print(\"PCA applied. \", end='')\n",
    "                    sampled_edges = graph_prep.perform_pca(sampled_edges)\n",
    "                else:\n",
    "                    print(\"PCA not applied.\")\n",
    "\n",
    "                # train-test split\n",
    "                X_train, X_test, y_train, y_test = graph_prep.edge_train_test_split(sampled_edges, sampled_labels, stratified=if_stratified)\n",
    "                print(\"Stratified Train-Test Split: \", if_stratified)\n",
    "\n",
    "                # LR\n",
    "                if classification_models[clf_idx] == 'lr':\n",
    "                    lr_clf = tune_hyperparameters(LogisticRegression(max_iter=100000), lr_param_dist, X_train, y_train)\n",
    "                    metrics, roc_data, prc_data = train_evaluate_model(lr_clf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "                # SVM\n",
    "                elif classification_models[clf_idx] == 'svm':\n",
    "                    svm_clf = tune_hyperparameters(SVC(probability=True), svm_param_dist, X_train, y_train)\n",
    "                    metrics, roc_data, prc_data = train_evaluate_model(svm_clf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "                # XGB\n",
    "                elif classification_models[clf_idx] == 'xgb':\n",
    "                    xgb_clf = tune_hyperparameters(xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgb_param_dist, X_train, y_train)\n",
    "                    metrics, roc_data, prc_data = train_evaluate_model(xgb_clf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "                elif classification_models[clf_idx] == 'softmax':\n",
    "                    nn_model = SoftmaxNN(X_train.shape[1])\n",
    "                    metrics = train_evaluate_nn(nn_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid value for classification model.\")\n",
    "\n",
    "\n",
    "                ##### Directory for saving results ######\n",
    "                save_dir = '../res/'+ classification_models[clf_idx]\n",
    "                os.makedirs(save_dir, exist_ok=True)\n",
    "                # Convert the metrics to a pandas DataFrame\n",
    "                metrics_df = pd.DataFrame([metrics])\n",
    "\n",
    "                #save the results\n",
    "                stratified = \"stratified\" if if_stratified else \"unstratified\"\n",
    "                pca = \"pca\" if if_PCA else \"\"\n",
    "                save_name = save_dir + '/' + embedding_methods[emd_idx] +'_'+ sampling +'_' + pca + stratified\n",
    "                # Export the DataFrame to a CSV file\n",
    "                metrics_df.to_csv(save_name+'.csv', index=False)\n",
    "                plot_metrics(roc_data, prc_data, save_fig=True, filename=save_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}